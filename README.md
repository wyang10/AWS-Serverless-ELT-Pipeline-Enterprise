<!--
 * @Author: Audrey Yang 97855340+wyang10@users.noreply.github.com
 * @Date: 2026-01-02 00:03:56
 * @LastEditors: Audrey Yang 97855340+wyang10@users.noreply.github.com
 * @LastEditTime: 2026-01-02 02:24:49
 * @FilePath: /AWS-Serverless-ELT-Pipeline-Enterprise/README-1.md
 * @Description: è¿™æ˜¯é»˜è®¤è®¾ç½®,è¯·è®¾ç½®`customMade`, æ‰“å¼€koroFileHeaderæŸ¥çœ‹é…ç½® è¿›è¡Œè®¾ç½®: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE
-->
# AWS Serverless ELT Pipeline â€” v2.0 (Enterprise-ready)

> è½»é‡èµ·æ­¥ï¼Œä¼ä¸šåŒ–èƒ½åŠ›éšå¼€éšç”¨ï¼š**S3 â†’ Lambda â†’ SQS â†’ Lambda â†’ S3(Parquet)**ï¼Œå¯é€‰ç¼–æ’ã€ç›®å½•ã€è´¨é‡é—¨ç¦ä¸å¯è§‚æµ‹æ€§ã€‚

This v2.0 elevates the minimal v1 into a **production-ready, enterprise-style** framework:
- **Orchestration (optional):** EventBridge â†’ Step Functions â†’ Glue Job (+ optional **Great Expectations** gate)
- **Catalog / Query (optional):** Glue Data Catalog + Crawler + Athena tables for **silver/** Parquet
- **Replay / Recovery:** `replay` & `redrive` scripts for backfill and poison-message recovery
- **Idempotency:** Object-level dedup via DynamoDB TTL (Powertools Idempotency)
- **CI/CD:** GitHub Actions CI (pytest + terraform fmt) + manual Terraform plan/apply (supports keys/OIDC)

---

## ğŸ§© Architecture

```

S3 (bronze/*.jsonl)
  â””â”€(ObjectCreated)
     Lambda ingest (Powertools logging/metrics + DynamoDB idempotency)
        â””â”€ SQS (events) â”€â”€(event source mapping)â”€â”€> Lambda transform (Parquet)
              â””â”€ DLQ (optional)
                                â””â”€ S3 (silver/*.parquet) â”€â”€> (optional) Glue Catalog & Athena

```

**No VPC / EC2 / API Gateway required** for the minimal path. API Gateway can be added later for sync APIs if needed.

---

## ğŸ” v1 vs v2.0

| Aspect | v1 (Minimal) | v2.0 (Enterprise-ready) |
|---|---|---|
| Pipeline | S3â†’Lambdaâ†’SQSâ†’Lambdaâ†’S3 | Same + Step Functions orchestration |
| Storage | JSONL â†’ Parquet | Parquet + Glue tables for Athena |
| Idempotency | DDB object-level lock | Powertools Idempotency (DynamoDB TTL) + replay/backfill |
| Replay / DLQ | Manual | `scripts/replay.sh`, `scripts/redrive.sh` |
| Observability | Logs only | (optional) CloudWatch Dashboards + Alarms |
| CI/CD | Manual apply | GitHub Actions CI + manual terraform plan/apply (keys/OIDC) |
| DQ | â€“ | Glue Job + optional Great Expectations gate |

---

## ğŸŒŸ What this framework gives you

- **ğŸš€ One-command deploy**: Terraform modules + per-env togglesï¼Œæ”¯æŒ GitHub Actions OIDCã€‚
- **ğŸ§± Robust by design**: å¯¹è±¡çº§å¹‚ç­‰ã€SQS å±€éƒ¨æ‰¹å¤±è´¥ã€DLQ redriveã€å¯å›æ”¾ã€‚
- **âš™ï¸ Easy extensibility**: `make scaffold DATASET=<name>` ç”Ÿæˆé…ç½®/å¤„ç†å™¨/DQ æ¨¡æ¿/æ ·ä¾‹ã€‚
- **ğŸ“Š Built-in observability**: (å¯é€‰) CloudWatch Dashboards & Alarmsã€‚
- **ğŸ” Query-ready**: (å¯é€‰) Glue Catalog + Crawler + Athena è¡¨ã€‚
- **âœ… Quality gate**: (å¯é€‰) GE è´¨é‡é—¨ç¦ï¼ˆGlue Job å†…è¿è¡Œï¼ŒStep Functions ç¼–æ’ï¼‰ã€‚

---

## ğŸ“ Repo Layout

```
repo-root/
â”œâ”€ README.md
â”œâ”€ ROADMAP.md
â”œâ”€ Makefile
â”œâ”€ templates/                   # scaffolding blueprints
â”œâ”€ scripts/
â”‚  â”œâ”€ gen_fake_events.py
â”‚  â”œâ”€ replay_from_s3.py         # S3â†’SQS ç›´æ¨ (éœ€è¦ sqs:SendMessage)
â”‚  â”œâ”€ replay.sh                 # S3 copy åˆ°æ–°çš„ bronze/ å‰ç¼€ï¼ˆæ¨èï¼Œæ— éœ€ SQS å‘ä¿¡æƒé™ï¼‰
â”‚  â”œâ”€ redrive.sh                # SQS åŸç”Ÿ redrive
â”‚  â””â”€ scaffold.sh               # ç”Ÿæˆ dataset éª¨æ¶
â”œâ”€ configs/                     # æ¯ä¸ª dataset çš„å…ƒé…ç½®
â”œâ”€ dq/                          # è½»é‡ DQ è§„åˆ™ï¼ˆæˆ–æ˜ å°„åˆ° GEï¼‰
â”œâ”€ data_samples/                # æ ·ä¾‹ JSON/JSONL
â”œâ”€ lambdas/
â”‚  â”œâ”€ ingest/
â”‚  â”‚  â”œâ”€ app.py
â”‚  â”‚  â”œâ”€ requirements.txt
â”‚  â”‚  â””â”€ tests/
â”‚  â”œâ”€ transform/
â”‚  â”‚  â”œâ”€ app.py
â”‚  â”‚  â”œâ”€ requirements.txt
â”‚  â”‚  â””â”€ tests/
â”‚  â””â”€ shared/
â”‚     â”œâ”€ init.py
â”‚     â”œâ”€ schemas.py
â”‚     â””â”€ utils.py
â””â”€ infra/
â””â”€ terraform/
â”œâ”€ backend/backend.hcl
â”œâ”€ modules/
â”‚  â”œâ”€ storage/            # S3 bronze/silver, notifications
â”‚  â”œâ”€ queue/              # SQS + DLQ
â”‚  â”œâ”€ lambdas/            # ingest / transform
â”‚  â”œâ”€ ddb/                # idempotency table (+ TTL)
â”‚  â”œâ”€ catalog/            # Glue DB + Crawler
â”‚  â”œâ”€ glue_job/           # Compaction / GE runner
â”‚  â”œâ”€ workflow_ops/       # EventBridge + Step Functions
â”‚  â””â”€ observability/      # Dashboards + Alarms
â””â”€ envs/
â””â”€ dev/
â”œâ”€ main.tf
â”œâ”€ dev.tfvars       # toggles: glue/ge/ops/observability
â””â”€ *.auto.tfvars.json  # ï¼ˆå¯é€‰ï¼‰æ³¨å…¥å¤–éƒ¨ SQS/ARN ç­‰

```

---

## ğŸ§° Prereqs

- Python **3.11+**
- Terraform **1.6+**
- AWS credentials for a **dev** account (region é»˜è®¤ `us-east-2`)
- (Optional) Docker

---

## âš¡ Quickstart

> é»˜è®¤åŒºåŸŸï¼š`us-east-2`ã€‚å¦‚æœä½ çš„ç»„ç»‡é™åˆ¶ CloudWatch `PutMetricAlarm/PutDashboard`ï¼Œå…ˆæŠŠ `observability_enabled=false`ï¼ˆè§ä¸‹æ–‡ï¼‰ã€‚

```bash
# 0) Setup
python3 -m venv .venv && source .venv/bin/activate
python -m pip install -U pip
python -m pip install -r requirements-dev.txt
export AWS_REGION=us-east-2
export AWS_DEFAULT_REGION=us-east-2
aws sts get-caller-identity   # ç¡®è®¤ Account/Arn

# 1) Build Lambda artifacts
make build

# 2) Terraform init + apply
make tf-init
TF_AUTO_APPROVE=1 make tf-apply

Upload a small seed to trigger the pipeline:

BRONZE=$(terraform -chdir=infra/terraform/envs/dev output -raw bronze_bucket)
python3 scripts/gen_fake_events.py --type shipments --count 50 --format jsonl --out /tmp/shipments.jsonl
aws s3 cp /tmp/shipments.jsonl "s3://$BRONZE/bronze/shipments/manual/shipments-$(date -u +%Y%m%dT%H%M%SZ).jsonl"

Check silver outputs:

SILVER=$(terraform -chdir=infra/terraform/envs/dev output -raw silver_bucket)
aws s3 ls "s3://$SILVER/silver/shipments/" --recursive | tail


â¸»

âœ… E2E Verification (one-liners)

# Who am I / region pinned
make verify-whoami

# Terraform outputs exist
make verify-tf-outputs

# S3 notifications wired (bronze -> ingest)
make verify-s3-notifications

# Lambdas reachable
make verify-lambdas

# DDB idempotency table + TTL
make verify-ddb

# SQS health + (optional) DLQ
make verify-sqs

# Seed end-to-end and verify silver
make verify-seed && make verify-silver

# Idempotency: same object twice â†’ second invoke skipped>=1
make verify-idempotency

# End to End Validation
make verify-e2e

å¦‚æœä½ æ–°æ’å…¥çš„å›¾ç‰‡æ¯”å¦‚ `![](demo/1.png)` æ˜¾ç¤ºä¸å‡ºæ¥ï¼Œé€šå¸¸æ˜¯ä¸‹é¢åŸå› ä¹‹ä¸€ï¼š

- æ–‡ä»¶è·¯å¾„ä¸å¯¹ï¼šGitHub å¯¹è·¯å¾„å¤§å°å†™æ•æ„Ÿï¼›è€Œä¸” `demo/1.png` å¿…é¡»çœŸçš„å­˜åœ¨ï¼ˆæœ¬ repo é‡Œé»˜è®¤æ˜¯ `demo/0-1.png`ã€`demo/dataset-scaffold.png` è¿™ç±»æ–‡ä»¶åï¼‰ã€‚
- å›¾ç‰‡è¿˜æ²¡è¢« git è·Ÿè¸ªï¼šæœ¬åœ°èƒ½çœ‹åˆ°ä½†æ²¡ `git add` / `git commit` / `git push`ï¼ŒGitHub ä¸Šå½“ç„¶ä¸ä¼šæœ‰ã€‚
- æ–‡ä»¶åæœ‰ç©ºæ ¼/æ‹¬å·/ä¸­æ–‡ï¼šç”¨ `![](<demo/ä½ çš„æ–‡ä»¶å (1).png>)` è¿™ç§å†™æ³•æ›´ç¨³ã€‚

å»ºè®®å…ˆè·‘ä¸€é”®ç‰ˆï¼ˆä¼šä¾æ¬¡æ‰§è¡Œå¤šæ­¥ CLI éªŒè¯ + é€ æ•° + ç­‰å¾… Silverï¼‰ï¼š

- `make verify-e2e`

![](<demo/0-1.png>)
![](<demo/0-2.png>)

â¸»

ğŸ§ª Idempotency Model
	â€¢	Scope: S3 object-level (bucket/key#etag)
	â€¢	Store: DynamoDB with TTL (Powertools Idempotency)
	â€¢	SQS consumer: partial batch failure + DLQ redrive è„šæœ¬

â¸»

ğŸ“š Catalog & Query (optional)

Enable Glue DB + Crawlerï¼ˆå¹¶ä¾› Athena æŸ¥è¯¢ï¼‰ï¼š

1. infra/terraform/envs/dev/dev.tfvarsï¼š

glue_enabled = true
# glue_silver_prefix = "silver/"
# glue_table_prefix  = "silver_"

2. éƒ¨ç½²ï¼š

TF_AUTO_APPROVE=1 make tf-apply
make glue-crawler-start
make glue-crawler-status

Then query in Athena:

SELECT dt, shipment_id, origin, destination, carrier, weight_kg, event_time
FROM "<glue_db>".silver
WHERE record_type='shipments'
ORDER BY dt DESC, event_time DESC
LIMIT 20;


â¸»

ğŸ§µ Step Functions & Quality Gate (optional)
	â€¢	Ops workflowï¼ˆreplay+quality pollingï¼‰ï¼šmodules/workflow_ops
	â€¢	Great Expectationsï¼šåœ¨ Glue Job å†…è·‘ï¼ˆå®¹å™¨åŒ–ä¾èµ–æ›´ç¨³å®šï¼‰ï¼Œç”± Step Functions è§¦å‘

Enabling flags in dev.tfvarsï¼ˆæŒ‰éœ€ï¼‰ï¼š

ops_enabled           = true
ge_enabled            = true
ge_workflow_enabled   = true
# ge_emit_events_from_transform = true   # transform æˆåŠŸåå‘ EventBridge è§¦å‘ GE
# ge_eventbridge_enabled        = true

Run:

make ops-start && make ops-status && make ops-history
make ge-start GE_RECORD_TYPE=shipments GE_DT=2025-12-31 GE_RESULT_PREFIX=ge/results
make ge-status


â¸»

ğŸ§¯ Replay / Recovery
	â€¢	S3-copy replayï¼ˆæ¨èï¼‰ï¼šæ— éœ€ sqs:SendMessageï¼Œè§¦å‘åŒä¸€æ¡ S3â†’ingestâ†’SQS è·¯å¾„ã€‚
	./scripts/replay.sh 2026-01-01T00:00:00Z 2026-01-02T00:00:00Z bronze/shipments/
	â€¢	Direct SQS replayï¼šéœ€è¦é˜Ÿåˆ—ä¸Šçš„ sqs:SendMessageã€‚
	python3 scripts/replay_from_s3.py --bucket "$BRONZE" --prefix bronze/shipments/ --queue-url "$(terraform -chdir=infra/terraform/envs/dev output -raw queue_url)"
	â€¢	DLQ redriveï¼ˆSQS åŸç”Ÿï¼‰ï¼š
	./scripts/redrive.sh

â¸»

ğŸ›¡ï¸ IAM / Org Gotchas
	â€¢	CloudWatchï¼šè®¸å¤šç»„ç»‡é™åˆ¶ cloudwatch:PutMetricAlarm / cloudwatch:PutDashboard
â†’ è®¾ç½® observability_enabled=false å†éƒ¨ç½²ã€‚
	â€¢	SQS Tag æƒé™ï¼šå¦‚æœç¼º sqs:ListQueueTags/TagQueueï¼ŒTerraform refresh/create å¯èƒ½æŠ¥é”™
â†’ é¢„åˆ›å»ºé˜Ÿåˆ—å¹¶å†™å…¥ *.auto.tfvars.jsonï¼ˆè®© TF åªå¼•ç”¨ï¼Œä¸ç®¡ç†ï¼‰ã€‚
	â€¢	IAM Role å‘½å/Tag é™åˆ¶ï¼šç”¨ iam_name_prefix ç»Ÿä¸€å‰ç¼€ï¼Œå¹¶ç¦ç”¨ IAM/SQS tagï¼ˆæœ¬ repo å·²é»˜è®¤å…³é—­ï¼‰ã€‚

â¸»

ğŸ§± CI/CD (GitHub Actions)
	â€¢	.github/workflows/ci.ymlï¼špytest + terraform fmt -check
	â€¢	.github/workflows/terraform-manual.ymlï¼šæ‰‹åŠ¨ plan/apply/destroyï¼ˆOIDC é¦–é€‰ï¼›æ— æ˜æ–‡å¯†é’¥ï¼‰

Secrets:
	â€¢	OIDCï¼šAWS_ROLE_TO_ASSUME
	â€¢	Keysï¼ˆå¦‚éœ€ï¼‰ï¼šAWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEYï¼ˆå¯é€‰ AWS_SESSION_TOKENï¼‰
	â€¢	å¯é€‰ï¼šTF_BACKEND_HCLï¼ˆè¿œç«¯ state é…ç½®ï¼›ä¸æä¾›æ—¶é™åˆ¶ apply/destroyï¼‰

â¸»

ğŸ§ª Dataset Scaffold

å¿«é€Ÿç”Ÿæˆä¸€ä¸ªæ–°æ•°æ®é›†éª¨æ¶ï¼š

make scaffold DATASET=ups_shipping
# å°†ç”Ÿæˆï¼š
#   configs/ups_shipping.yaml
#   lambdas/transform/ups_shipping/handler.py
#   dq/ups_shipping/rules.yaml
#   data_samples/ups_shipping/sample.jsonl

è°ƒæ•´ configs/<dataset>.yamlï¼ˆprefix/idempotency_key/output columnsï¼‰ï¼Œå®ç° handler æ˜ å°„é€»è¾‘ï¼Œå³å¯æ¥å…¥ã€‚

â¸»

ğŸ§¹ Cleanup

S3 å¿…é¡»å…ˆæ¸…ç©ºå† destroyï¼š

TF_AUTO_APPROVE=1 make tf-destroy || true

BRONZE=$(terraform -chdir=infra/terraform/envs/dev output -raw bronze_bucket)
SILVER=$(terraform -chdir=infra/terraform/envs/dev output -raw silver_bucket)
aws s3 rm "s3://$BRONZE" --recursive || true
aws s3 rm "s3://$SILVER" --recursive || true

TF_AUTO_APPROVE=1 make tf-destroy


â¸»

ğŸ—ºï¸ Changelog v2.0
	1.	è§¦å‘ç¼–æ’ï¼šEventBridge â†’ Step Functionsï¼ˆDQ é˜¶æ®µï¼‰ï¼ŒTask è·‘ Glue Jobï¼ˆå¯é€‰æ¥ GEï¼‰
	2.	å¯æŸ¥è¯¢ç»ˆç‚¹ï¼šæ³¨å†Œ Glue Catalog + Athena è¡¨ï¼ˆsilver/*.parquetï¼‰
	3.	å›æ”¾é—­ç¯ï¼š`scripts/replay.sh` / `scripts/replay_from_s3.py` + `scripts/redrive.sh`ï¼ˆDLQ â†’ ä¸»é˜Ÿåˆ—ï¼‰
	4.	å¹‚ç­‰ç»†èŠ‚ï¼šå¯¹è±¡çº§å¹‚ç­‰ï¼ˆS3 bucket/key#etagï¼‰ï¼ŒPowertools Idempotency + DynamoDB TTL
	5.	CI/CDï¼šGitHub Actionsï¼ˆpytest + terraform fmtï¼›æ‰‹åŠ¨è§¦å‘ terraform plan/applyï¼›æ”¯æŒ keys/OIDCï¼‰

â¸»

ğŸ“„ blurb 

- AWS Serverless ELT Pipeline (v2.0 / Enterprise) â€” S3 â†’ Lambda â†’ SQS â†’ Lambda â†’ S3 (Parquet)
- Added Step Functions orchestration, Glue Data Catalog/Athena, and a GE data-quality gate.
- Implemented DynamoDB-based idempotency (TTL), DLQ/redrive & replay tooling, and GitHub Actions CI/CD via OIDC.
- Production-ready, extensible template: per-dataset scaffold, observable, and recovery-friendly.

â¸»

License

MIT
